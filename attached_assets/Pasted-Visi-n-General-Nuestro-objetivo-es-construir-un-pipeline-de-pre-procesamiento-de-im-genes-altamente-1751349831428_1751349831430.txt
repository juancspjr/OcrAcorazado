Visión General:
Nuestro objetivo es construir un pipeline de pre-procesamiento de imágenes altamente eficiente y seguro, capaz de transformar cualquier comprobante bancario digital (principalmente capturas de pantalla horizontales) en un formato ideal para el Reconocimiento Óptico de Caracteres (OCR). Esto significa garantizar que el texto aparezca en negro sobre un fondo blanco puro o un fondo suficientemente claro y uniforme, maximizando la precisión de la extracción de datos y minimizando los errores, incluso ante imágenes desafiantes o previamente procesadas de manera imperfecta.

Este sistema no solo aplica reglas fijas, sino que analiza dinámicamente la entrada para adaptar sus técnicas, priorizando la integridad de los datos, la eficiencia computacional y, fundamentalmente, la conservación extrema de la forma y la integridad de cada carácter.

Fase 1: Evaluación Inteligente y Triage de Imágenes (El "Primer Ojo" del Sistema)
Antes de cualquier procesamiento pesado, el sistema realiza una evaluación rápida para determinar la viabilidad y el estado inicial de la imagen.

Evaluación de Viabilidad y Detección de Daño Crítico:

Análisis: Se inspecciona la imagen en un nivel macro para detectar un posible daño catastrófico que impida cualquier reconocimiento significativo. Esto incluye:

Dispersión de Píxeles: Si la imagen consiste en una dispersión aleatoria de píxeles negros sobre blanco (o viceversa) sin estructuras de caracteres reconocibles.

Contraste Cero: Ausencia total de contraste entre el "texto" y el "fondo".

Tamaño/Dimensiones Irregulares: Imágenes con dimensiones extremadamente pequeñas o distorsionadas que sugieran corrupción.

Decisión del Sistema: Si se detecta un daño crítico, la imagen se marca instantáneamente como "No Procesable por OCR". Se genera un registro de error y se deriva para revisión humana o descarte, evitando el consumo inútil de recursos en fases posteriores.

Justificación: Un paso crítico para la eficiencia y seguridad. No tiene sentido procesar una imagen ilegible; esto previene falsos positivos, consume tiempo y puede generar resultados erróneos.

Análisis Profundo del Estado Visual (para Imágenes Viables):

Paso Inicial: Convertir la imagen viable a escala de grises. Este es el punto de partida para evaluar tonalidades.

Detección de Tonalidad y Contraste (y posible Binarización/Inversión previa):

Análisis: El sistema evalúa la distribución de colores y la luminosidad general. Determina si la imagen es:

Original/Colorida: (ej. Imagen de WhatsApp 2025-06-21 a las 18.44.16_564ec301.jpg - fondo claro, texto oscuro, elementos de color).

Binarizada (Texto Negro sobre Blanco): (ej. imagen_mejorada(2).jpg - ya cerca del ideal).

Binarizada Invertida (Texto Blanco sobre Negro): (ej. 20250630_153121_587_enhanced_image.jpg - fondo negro, texto blanco).

Implicaciones para OCR: Esta detección temprana informa las decisiones de pre-procesamiento subsiguientes. Un bajo contraste original requiere un realce más agresivo. La binarización invertida exige una reversión inmediata.

Claridad, Nitidez y Grosor de Caracteres (con Enfoque en la Conservación):

Análisis: Se examinan los bordes de los caracteres (¿son nítidos o borrosos?), su grosor (¿son finos, normales, o gruesos?) y la uniformidad de la fuente. Se busca específicamente la presencia de halos o bordes residuales no deseados, especialmente en imágenes ya binarizadas. La prioridad aquí es identificar cualquier imperfección que pueda distorsionar la forma original de la letra.

Implicaciones para OCR: Determina la necesidad de aplicar filtros de agudizado, operaciones morfológicas de engrosamiento/adelgazamiento o técnicas de limpieza de bordes, siempre con la premisa de no alterar la forma intrínseca de la letra, solo realzarla.

Detección de Ruido y Artefactos (Minimización del Impacto en Caracteres):

Análisis: Identificación de motas, manchas, artefactos de compresión (JPEG), o cualquier elemento que no sea texto o parte esencial del layout.

Implicaciones para OCR: El nivel y tipo de ruido dicta la fuerza de los filtros de denoising, asegurando que su aplicación no degrade la estructura de los caracteres.

Evaluación de Orientación (confirmación de horizontalidad):

Análisis: Se verifica la perfecta alineación horizontal del texto. Dada la naturaleza de las capturas de pantalla, se asume que el texto es predominantemente horizontal.

Implicaciones para OCR: Se valida que no hay rotaciones inesperadas que puedan afectar la lectura, aunque no se requiere un algoritmo de corrección de sesgo complejo.

Identificación de Elementos Gráficos No Textuales e Interferencias:

Análisis: Detección de logotipos, iconos y otros elementos que pueden confundir al OCR, más allá del texto puro.

Implicaciones para OCR: Estos elementos deberán ser neutralizados o aislados si interfieren con la lectura del texto.

Nivel 2: Clasificación de Características Dominantes
Detección de Tonalidad General y Contraste (Predominante):

Característica Clave a Detectar: La relación dominante entre la luminosidad del texto y el fondo.

Posibilidades Detectadas (y sus Implicaciones):

Caso A: Fondo Oscuro, Letras Claras (Tonos Grises, Blancos, o con Bordes Claros):

Descripción: Incluye "fondo oscuro, letras claras tonos grises", "letras pequeñas con fondo oscuro en grises", y "fondo oscuro con letras con bordes claros y color oscuro coincidiendo con el fondo" (ej., Imagen de WhatsApp 2025-06-20 a las 20.21.31_7a06b961.png).

Influencia en Lectura: Dificulta la binarización directa; requiere una inversión y un ajuste de contraste preciso para oscurecer el texto y blanquear el fondo.

Estrategia Propuesta: Aplicar estrategia de "punto de referencia medio" (ver Nivel 3).

Caso B: Fondo Claro (Blanco/Muy Claro), Letras Negras/Muy Oscuras (Nítidas - Ideal):

Descripción: "letras negras fondo blanco o muy claro nítidas ideal para el procesamiento" (ej., imagen_mejorada(2).jpg).

Influencia en Lectura: Óptimo. Requiere mínimo ajuste de contraste, binarización suave.

Estrategia Propuesta: Binarización directa con umbral conservador (ver Nivel 3).

Caso C: Combinación de Fondos (Complejo y Crítico):

Descripción: "combinaciones de dos o más tipos de fondo donde las letras son contrastadas (ej. fondo negro con letras claras, en la misma imagen fondo claro con letras negras)".

Influencia en Lectura: El mayor desafío. Los ajustes globales pueden perjudicar una de las secciones, y la inversión indiscriminada dañaría la otra.

Estrategia Propuesta: Binarización adaptativa local con inversión condicionada a la región y ajuste de contraste unificado (ver Nivel 3).

Nivel 3: Transformación Dinámica y Optimización con Conservación Extrema de Caracteres
Principio Clave: El objetivo final es siempre texto negro uniforme sobre un fondo suficientemente claro, garantizando la máxima calidad, nitidez y conservación de la forma de las letras y la separación efectiva del fondo. La "nitidez suficiente" para el OCR es prioritaria sobre un blanco puro si esto compromete la integridad de las letras; basta con que sea lo suficientemente claro para la lectura del OCR. El punto ideal de contraste para OCR se sitúa en un rango donde el texto es significativamente más oscuro que el fondo, sin que el texto se "rellene" ni el fondo se "oscurezca" excesivamente, manteniendo los bordes definidos.

Normalización de Color y Binarización Inteligente (Aplicación de Estrategia de Contraste):

Para Caso A (Fondo Oscuro, Letras Claras):

Técnica:

Binarización inicial de la imagen en escala de grises.

Detección y Corrección de Inversión: El sistema detecta que el fondo es mayoritariamente negro y las letras blancas.

Inversión Inmediata de Colores: Se invierten los colores para obtener texto negro sobre fondo blanco.

Ajuste de Contraste "Punto de Referencia Medio" (Post-Inversión):

Calcular la media de luminosidad (M 
total
​
 ) de todos los píxeles de la imagen (ahora con texto negro sobre fondo blanco). Este M 
total
​
  servirá como nuestro umbral de referencia para separar conceptualmente el texto del fondo.

Identificar el rango de luminosidad del texto (L 
texto
​
 ) y el rango de luminosidad del fondo (L 
fondo
​
 ) alrededor de M 
total
​
 . Por ejemplo, píxeles <M 
total
​
  son potencialmente texto, y píxeles >M 
total
​
  son potencialmente fondo.

Aplicación Real con Cálculos:

Asumamos una imagen binarizada invertida donde el texto (ahora negro/gris oscuro) tiene un valor promedio de luminosidad de 50 y el fondo (ahora blanco/gris claro) tiene un valor promedio de 200. El rango de grises es 0−255.

El "punto de referencia medio" podría ser el umbral de binarización inicial, digamos M 
binarizacion
​
 .

Oscurecer Letras: Para los píxeles con luminosidad L≤M 
binarizacion
​
  (que son letras), el nuevo valor de luminosidad L 
nuevo
​
  se calcula como: L 
nuevo
​
 =max(0,L−ΔL 
texto
​
 ). Donde ΔL 
texto
​
  es un valor positivo (ej. 20−50) que oscurece el píxel. Si L=50 y ΔL 
texto
​
 =30, L 
nuevo
​
 =20. Esto garantiza que las letras se vuelvan más negras, pero con un límite mínimo de 0 para no "sobre-oscurecer".

Aclarar Fondo: Para los píxeles con luminosidad L>M 
binarizacion
​
  (que son el fondo), el nuevo valor de luminosidad L 
nuevo
​
  se calcula como: L 
nuevo
​
 =min(255,L+ΔL 
fondo
​
 ). Donde ΔL 
fondo
​
  es un valor positivo (ej. 20−50) que aclara el píxel. Si L=200 y ΔL 
fondo
​
 =30, L 
nuevo
​
 =230. Esto asegura que el fondo se aclare, con un límite máximo de 255.

Los valores ΔL 
texto
​
  y ΔL 
fondo
​
  no son fijos ("-10, 0, 10"), sino que se determinan dinámicamente o experimentalmente para lograr un balance óptimo sin comprometer la forma del carácter. Si las letras son muy finas, ΔL 
texto
​
  podría ser menor para evitar que desaparezcan. Si el fondo tiene sutiles variaciones, ΔL 
fondo
​
  podría ser ajustado para no generar ruido.

Justificación: Oscurece selectivamente las letras manteniendo su forma y blanquea el fondo para un contraste óptimo, sin buscar un blanco puro (255) si eso implica daño a los caracteres, sino una nitidez suficiente para el OCR.

Para Caso B (Fondo Claro, Letras Negras - Ideal):

Técnica:

Binarización adaptativa (ej., Otsu local) con un umbral conservador, calibrado para no dañar los bordes de los caracteres.

Verificación de No Inversión: Se confirma que el fondo es blanco y el texto negro.

Ajuste de Contraste Suave (Si Necesario): Pequeños ajustes (similares a ΔL 
texto
​
  y ΔL 
fondo
​
  pero con valores menores, ej. ±5−10) para asegurar que el fondo sea suficientemente claro (ej. L 
fondo
​
 >200) y el texto suficientemente oscuro (ej. L 
texto
​
 <50), sin afectar la forma de las letras.

Para Caso C (Combinación de Fondos - Estrategia Avanzada):

Técnica:

Detección de Regiones Homogéneas: El sistema utiliza análisis de vecindad y segmentación para identificar las distintas regiones de fondo (oscuro vs. claro) dentro de la misma imagen.

Binarización Adaptativa Local con Inversión Condicionada: Para cada región detectada:

Si una región tiene un fondo oscuro y letras claras, se le aplica una inversión de color LOCAL para que el texto sea negro y el fondo blanco, sin afectar las otras regiones.

Si una región tiene un fondo claro y letras oscuras, se mantiene tal cual.

Unificación de Tonalidades de Fondo (Post-Inversión Local): Una vez que todas las letras están negras, se unifican las tonalidades de los fondos ahora claros. Se aplica la estrategia de "punto de referencia medio" global o segmentada si es necesario, buscando que todos los fondos queden en un rango de claridad óptimo (ej. L 
fondo
​
 >200), priorizando la no alteración del carácter. El objetivo es que el fondo sea uniforme y suficientemente claro, no necesariamente 255 si eso degrada los caracteres.

Post-Procesamiento de Consolidación: Tras las operaciones locales, se aplican operaciones morfológicas muy sutiles para suavizar posibles uniones o bordes extraños entre las regiones procesadas, garantizando que la forma de las letras no se vea comprometida.

Justificación: Esta estrategia maneja la complejidad de fondos múltiples al aplicar transformaciones solo donde son necesarias, evitando el daño a las secciones ya correctas y asegurando un contraste ideal en toda la imagen, siempre con la premisa de la conservación del carácter.

Validación Temprana por OCR (Salida Temprana para Eficiencia):

Punto de Control: Antes de la limpieza de ruido y perfeccionamiento de bordes más intensivo.

Técnica: Se ejecuta un OCR preliminar sobre la imagen binarizada y con contraste ajustado. Se intenta extraer los campos críticos predefinidos: Monto Total, Punto de Referencia/Operación, Beneficiario (nombre/razón social), Cédula/Número de Celular, y Cuenta Bancaria del Beneficiario.

Condición de Éxito: Si el margen de confianza del OCR para todos estos campos críticos es alto (ej., >95%) y los datos extraídos cumplen con las validaciones de formato básicas.

Decisión del Sistema:

Si SÍ (Confianza Alta en Campos Críticos): El sistema considera que el objetivo de extracción ha sido superado en esta etapa.

Acción: Se procede directamente a la Fase 4 para la ejecución final del OCR y la validación de todos los datos extraíbles. Se omiten los pasos de "Limpieza de Ruido y Perfeccionamiento de Bordes" y "Neutralización de Elementos Gráficos No Textuales" (o se aplican de forma muy ligera y condicional) para maximizar la eficiencia.

Justificación: El objetivo es la eficiencia. Si los datos clave ya son legibles con alta confianza, el procesamiento adicional es innecesario y podría introducir riesgos de daño.

Si NO (Confianza Baja o Campos Críticos Ausentes):

Acción: Continuar con los pasos de pre-procesamiento restantes (Limpieza de Ruido, Neutralización de Gráficos, etc.) para mejorar la calidad y reintentar el OCR.

Justificación: La imagen aún requiere optimización para lograr la precisión deseada.

Limpieza de Ruido y Perfeccionamiento de Bordes (La "Pulidora Precisa" que No Altera - Solo si no hubo Salida Temprana):

Técnica (Aplicado Post-Binarización/Inversión y Ajuste de Contraste):

Denoising (No Invasivo): Filtros (mediana, gaussiano) aplicados con kernels pequeños para suavizar ruido sin distorsionar ni difuminar los bordes de los caracteres.

Operaciones Morfológicas Condicionales y Delicadas:

Adelgazamiento/Engrosamiento (Muy Sutil): Si el análisis del grosor del carácter lo requiere, se aplican erosiones o dilataciones con kernels de 1x1 o 2x2 píxeles, en una única iteración o un número mínimo, solo para corregir rupturas menores o fusiones. El objetivo es consolidar la forma, no alterarla.

Limpieza de Contornos/Halos: Utilizar operaciones de detección de contornos para identificar cualquier borde o "sombra" blanca persistente alrededor de los caracteres o en el fondo. Estos elementos se "rellenan" con blanco puro o con la tonalidad de blanco más clara del fondo circundante, asegurando que el fondo sea impecable sin invadir los caracteres.

Justificación: Elimina artefactos que confunden al OCR y perfecciona la apariencia de los caracteres, con la máxima prioridad en la preservación de su geometría original.

Neutralización de Elementos Gráficos No Textuales (Cuidado Extremo - Solo si no hubo Salida Temprana):

Técnica: Identificar y, si es estrictamente necesario, rellenar con blanco puro los logotipos, iconos o líneas decorativas que evidentemente no son texto y que la experiencia ha demostrado que interfieren directamente con la lectura de los campos clave. Esto se hará con un enfoque conservador, priorizando no eliminar información potencialmente útil o dañar caracteres cercanos. Solo se actuará sobre objetos no conectados a las regiones de texto y cuando su interferencia sea comprobada.

Justificación: Previene falsos positivos del OCR y mantiene la limpieza, ejerciendo extrema precaución para no afectar ningún carácter ni dato relevante.

Normalización de Escala y Resolución:

Técnica: Redimensionar la imagen a un DPI óptimo (ej., 300 DPI) usando algoritmos de interpolación de alta calidad (ej., bicúbica) para mantener la nitidez y el detalle de los caracteres durante el escalado.

Justificación: Consistencia para el OCR y preservación de la calidad del carácter.

Nivel 4: Ejecución Robusta del OCR y Validación Post-Extracción
Configuración Optimizada del OCR (ej., Tesseract):

Parámetros: --psm 6 (asume un solo bloque uniforme), --oem 3 (motor híbrido para precisión), -l spa (idioma español).

Whitelists/Blacklists: Uso de listas de caracteres permitidos para campos específicos (ej. 0-9 para montos), incrementando la precisión y seguridad al limitar posibles errores de reconocimiento y reforzar la lectura correcta de las formas conservadas.

Extracción Estructurada y Validación de Datos (Exhaustiva):

Extracción: Aplicar expresiones regulares o modelos de extracción de datos para identificar TODOS los campos relevantes (Fecha, Monto, Referencia, Banco Emisor, Banco Receptor, Beneficiario (nombre/razón social), Cédula/Número de Celular, Cuenta Bancaria del Beneficiario, Hora, Tipo de Transacción, etc.). Se buscará extraer la mayor cantidad de información posible.

Validación de Formato: Confirmar que los datos extraídos cumplen con las reglas (ej., formato de fecha, numérico para montos, longitud de cédula/cuenta).

Monitoreo de Confianza y Detección de Anomalías:

El sistema registra la puntuación de confianza del OCR para cada campo extraído.

Las extracciones con baja confianza (por debajo de un umbral predefinido, ej. <85%) o que no superen la validación de formato se marcan como anomalías.

Registro Integral (Log de Auditoría y Trazabilidad):

Se documenta cada paso: resultado del triage, clasificaciones de tonalidad, parámetros de binarización/morfología aplicados, resultados de OCR (todos los campos extraídos), confianza por campo, y la lista de anomalías. Esto asegura trazabilidad completa y seguridad.

