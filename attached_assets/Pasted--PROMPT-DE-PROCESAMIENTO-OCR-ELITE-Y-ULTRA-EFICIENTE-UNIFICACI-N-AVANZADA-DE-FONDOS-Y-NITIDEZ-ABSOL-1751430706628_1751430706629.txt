"PROMPT DE PROCESAMIENTO OCR ELITE Y ULTRA-EFICIENTE: UNIFICACIÓN AVANZADA DE FONDOS Y NITIDEZ ABSOLUTA DEL TEXTO"



OBJETIVO GENERAL:

Lograr la extracción del 100% de todo el texto legible de la imagen mediante OCR, garantizando la captura de cada carácter sin pérdidas y maximizando la velocidad y la fiabilidad de la extracción. La prioridad es la **transformación inteligente de múltiples y distintos tipos de fondo presentes en la imagen hacia un fondo blanco muy claro y uniforme** (valores de píxel predominantemente en el rango de 245-255 en escala de grises). Este proceso debe realizarse **sin eliminar, dañar ni alterar de ninguna manera las letras, números o signos de puntuación de escritura**, los cuales deben resultar en un **negro muy oscuro y de NITIDEZ ABSOLUTA** (valores de píxel predominantemente en el rango de 0-10 en escala de grises), facilitando su lectura óptima por el OCR. La eliminación de otros elementos no textuales (logos, símbolos) solo ocurrirá si son intrínsecamente parte de un "fondo" que debe unificarse o si su naturaleza los hace indistinguibles del ruido al intentar preservar el texto.



ESTRATEGIA CENTRAL:

El proceso se centrará en un pipeline de pre-procesamiento de imagen extremadamente eficiente y modular, con un énfasis supremo en la **binarización adaptativa localizada**, la **normalización de fondos complejos** y la **nitidez forense del texto**. Esto permitirá transformar una imagen con múltiples secciones de fondo en un lienzo binario unificado (fondo claro, texto oscuro) de calidad élite, que a su vez hará posible una *única y altamente eficiente pasada de OCR* sobre ella, eliminando cualquier procesamiento redundante. La "conservación extrema de caracteres" será la filosofía guía, priorizando la lectura completa y la integridad de la morfología del texto, incluso en presencia de fondos complejos o elementos no textuales incrustados.



PASOS DETALLADOS DEL PROCESO DESCRIPTIVO (SIN CÓDIGO - SÓLO CONCEPTO):



**ETAPA 1: DIAGNÓSTICO INTELIGENTE Y PRE-NORMALIZACIÓN (`validador_ocr.py`)**

* **Análisis Rápido de Calidad Inicial**: Evalúa métricas esenciales como contraste general, presencia de ruido, nitidez y resolución. Esto guía la aplicación *condicional* de pasos de mejora posteriores.

* **Detección Inmediata de Inversión de Colores**: Si la imagen presenta texto claro sobre fondo oscuro, se invierte la coloración en este punto temprano del pipeline. Esto asegura que todas las etapas subsiguientes trabajen con texto oscuro sobre fondo claro.

* **Análisis de Histograma y Rangos de Tonalidad Global/Local**: Se realiza un análisis detallado del histograma de la imagen en escala de grises para identificar los rangos de píxeles predominantes que representan el "fondo" y el "texto" a nivel global y, crucialmente, **detecta variaciones significativas de luminosidad o tonalidad que indiquen múltiples secciones de fondo**. Esta información es esencial para informar los umbrales de binarización adaptativa y los ajustes de normalización de niveles.



**ETAPA 2: PRE-PROCESAMIENTO ADAPTATIVO Y UNIFICACIÓN DE FONDOS ELITE (`mejora_ocr.py`)**

* **Redimensionamiento Condicional e Inteligente**: La imagen solo se redimensiona (aumenta) si su resolución es detectada como críticamente baja para OCR (ej., por debajo de 200-300 DPI). Se utiliza un algoritmo de interpolación que prioriza la conservación de los bordes del texto.

* **Suavizado de Ruido Mínimo y Dirigido (Condicional)**: Se aplican filtros de suavizado no destructivos (ej., bilateral, suavizado gaussiano) de forma *condicional*, solo si el diagnóstico de la Etapa 1 revela la presencia de ruido significativo. Los parámetros se ajustan finamente para eliminar el ruido sin difuminar los detalles críticos del texto, preservando las fronteras entre distintas áreas de fondo.

* **Binarización Adaptativa Ultra-Precisa para Fondos Heterogéneos (Umbral Inteligente y Rango de Salida Controlado)**:

    * Este es el paso más crítico para unificar fondos. Se aplica un algoritmo de binarización **altamente adaptativa y fuertemente local** (ej., métodos basados en Niblack, Sauvola, u Otsu con un tamaño de ventana local optimizado y un umbral de desviación adaptable). Este algoritmo debe ser intrínsecamente capaz de manejar **múltiples y distintos fondos dentro de la misma imagen**, calculando umbrales de forma local para cada micro-región de la imagen.

    * El objetivo es que, para cada área localizada, los píxeles del fondo sean empujados al rango de **blanco muy claro y uniforme (245-255)** y los píxeles del texto al rango de **negro muy oscuro y nítido (0-10)**. Esto **unificará visualmente todos los fondos variados a un blanco claro** y homogéneo, mientras que el texto mantendrá su contraste oscuro, **sin alterar los caracteres**.

* **Refuerzo de Bordes de Caracteres con NITIDEZ ABSOLUTA (Post-Binarización y Protección de Morfología)**: Tras la binarización y como un paso fundamental, se aplica un **`unsharp_mask` o un filtro de realce de bordes de ALTA POTENCIA y PRECISION QUIRÚRGICA** sobre las áreas donde se ha detectado texto. Este filtro será calibrado para acentuar la **NITIDEZ EXTREMA** de los contornos de las letras y números contra el fondo ya estandarizado, asegurando que cada carácter tenga bordes perfectamente definidos y una claridad inigualable para el OCR, **sin crear artefactos, sobreexponer ni comprometer la morfología original del carácter**.

* **Purificación y Limpieza Residual (Priorizando el Fondo y No-Texto)**:

    * **Análisis de Componentes Conectados (CCA) Enfocado en Fondo/Ruido**: Todos los grupos de píxeles conectados son identificados.

    * **Filtrado por Heurísticas de "No-Texto" o "Ruido de Fondo Remanente"**: Se aplican filtros para eliminar componentes que claramente NO son texto, pero el énfasis es en los que son residuos de fondo no unificado o ruido estructural. Se eliminan componentes:

        * Demasiado pequeños (ruido residual).

        * Que no cumplen con las proporciones esperadas de caracteres (ej., líneas muy finas que no son subrayados de texto, manchas difusas, puntos aislados).

        * Que, por su tamaño o forma, son claramente elementos gráficos de fondo que no se unificaron completamente y podrían confundir al OCR si se interpretan como texto.

    * **OPERACIÓN CRÍTICA: "Relleno Inteligente de Fondo"**: Cualquier área que, después de la binarización adaptativa y el filtrado, aún presente un fondo no uniforme o variaciones de tonalidad (pequeñas secciones que no se volvieron blanco claro), será identificada y "rellenada" con el color blanco muy claro estandarizado, **sin tocar las regiones que contienen texto o los píxeles de texto.** Esto asegura que toda la superficie que no es texto se convierta en un fondo unificado.

* **Operaciones Morfológicas Finales (Condicionales y Micro-Controladas)**: Se aplican operaciones de erosión/dilatación (ej., `skimage.morphology.remove_small_holes` para rellenar huecos internos en letras, o `morphology.thin` para adelgazar caracteres excesivamente gruesos) de forma *condicional y con parámetros mínimos*. Solo se ejecutan si el diagnóstico posterior indica letras rotas o pegadas que necesitan ser corregidas para mejorar la lectura, siempre protegiendo la forma de los caracteres.



**ETAPA 3: EXTRACCIÓN OCR DE ALTA EFICIENCIA (`aplicador_ocr.py`)**

* **OCR de Una Única Pasada Óptima**: La imagen, tras ser meticulosamente pre-procesada a su estado binario ideal, con su fondo unificado y el texto con **nitidez absoluta**, se envía a Tesseract para una *sola y completa extracción de texto*. Se suprime por completo la lógica del "dual-pass" y la extracción específica de "zonas grises", ya que la calidad de la imagen de entrada garantiza una lectura superior en una sola pasada.

* **Configuración de Tesseract Sintonizada**: Se utiliza una configuración de Tesseract que prioriza la velocidad y la precisión sobre esta entrada de imagen de alta calidad, maximizando el rendimiento sin errores.

* **Validación de Confianza del OCR**: Se mantiene y refina un filtrado del texto extraído basado en un umbral de confianza para asegurar que solo los segmentos de texto con una alta fiabilidad sean considerados válidos, minimizando la inclusión de "lecturas fantasma".

* **Post-Procesamiento de Cadenas de Texto Ágil**: El procesamiento posterior de las cadenas de texto extraídas se optimiza para ser lo más eficiente posible, dada la alta calidad del OCR. Se enfoca en reglas ligeras para:

    * Correcciones menores de segmentación (ej., separar números o palabras que Tesseract pudo haber pegado).

    * Limpieza de espacios, saltos de línea y caracteres especiales no deseados.

    * Estandarización de formatos básicos (ej., fechas, números).

* **Extracción y Validación Reforzada de Datos Financieros**: Se aplican expresiones regulares robustas y lógicas de validación de formato sobre el texto final para identificar y extraer de forma fiable todos los elementos financieros clave (montos, fechas, números de cuenta, operaciones, etc.), aplicando una segunda capa de corrección si es necesario (ej. pequeñas variaciones en números).



**ETAPA 4: CONSOLIDACIÓN Y REPORTE CLARO (`main_ocr_process.py`)**

* **Consolidación Simplificada**: Dada la ausencia del "dual-pass" y la alta calidad de la única extracción OCR, la etapa de consolidación es directa, simplemente orquestando la recepción y el empaquetado del resultado final.

* **Generación de Reporte Detallado**: Se compila un informe JSON estructurado que incluye el texto extraído completo, los datos financieros identificados, y las métricas de calidad y confianza finales del proceso.

* **Limpieza de Recursos**: Se asegura la eliminación eficiente de todos los archivos temporales intermedios creados durante el procesamiento.



RESULTADO FINAL ESPERADO:

La aplicación procesará imágenes con una velocidad significativamente superior y una fiabilidad del 100% en la extracción de texto. La imagen intermedia, si se guarda para auditoría, reflejará un estándar de calidad elite: un fondo **blanco muy claro y perfectamente uniforme en toda su extensión**, incluso si la imagen original presentaba múltiples y distintos tipos de fondo. Los caracteres resultarán en **negro muy oscuro y con NITIDEZ ABSOLUTA**, facilitando la inspección visual. Esto garantiza la lectura completa para el OCR, **sin perder ningún detalle del texto original** (incluyendo inclinaciones, negritas, tachados o subrayados). El output final será preciso, completo y absolutamente libre de redundancias o datos faltantes, con la certeza de que el fondo ha sido unificado y el texto maximizado en claridad sin afectar los caracteres críticos.